{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18aef592",
   "metadata": {},
   "source": [
    "## TF-IDF for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1987b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b33eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train = pd.read_csv(\"news_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33d2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = [simple_preprocess(line) for line in news_train['cleaned_words']]\n",
    "train_dict = corpora.Dictionary()\n",
    "train_corpus = [train_dict.doc2bow(line, allow_update=True) for line in train_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6759404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = TfidfModel(train_corpus, smartirs='ntc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93441f87",
   "metadata": {},
   "outputs": [],
   "source": [
    " # apply model to the first corpus document\n",
    "vector = train_tfidf[train_corpus[0]] \n",
    "\n",
    "#etc for other docs in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8563f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3899757375336991),\n",
       " (1, 0.45716592324545857),\n",
       " (2, 0.14915494661219156),\n",
       " (3, 0.3265268032796511),\n",
       " (4, 0.2140317550860369),\n",
       " (5, 0.2959838858806),\n",
       " (6, 0.1991798419941692),\n",
       " (7, 0.13450994338932348),\n",
       " (8, 0.16011292944815195),\n",
       " (9, 0.4259774812878671),\n",
       " (10, 0.2145638580082504),\n",
       " (11, 0.2563963538770435)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d5a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=104651, num_nnz=1769515)\n",
      "[(12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1)]\n",
      "[(12, 0.19625959819721403), (13, 0.18114835462564435), (14, 0.1442343339923965), (15, 0.23020045613760776), (16, 0.1215821887009755), (17, 0.2899603875144407), (18, 0.3392770863731662), (19, 0.17358249142787363), (20, 0.25704246343193127), (21, 0.16477335472980023), (22, 0.4250038937385465), (23, 0.2115885821189835), (24, 0.17199755598460853), (25, 0.37272612481649886), (26, 0.26182342144952586), (27, 0.23472115669795413)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.matutils import corpus2dense\n",
    "print(train_tfidf)\n",
    "print(train_corpus[1])\n",
    "print(train_tfidf[train_corpus[1]])\n",
    "dense_vec = corpus2dense(train_tfidf[train_corpus[1:5]], num_terms=train_tfidf.num_nnz).transpose()\n",
    "dense_vec\n",
    "#corpus_tfidf_sparse = corpus2csc(corpus_tfidf, num_terms, num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0134a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This cell should fit the pca in batches #####\n",
    "from gensim.matutils import corpus2dense\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca = IncrementalPCA(n_components=3) ###n_components will determine the number of dimensions to keep after applying dimensionality reduction.\n",
    "i=0\n",
    "batch_size=10 ###If you set the batch size to 1, it will throw an error, since the slice will no longer be a list of lists\n",
    "while True:\n",
    "    #####Temp is a numpy array corresponding to the dense rows generated from the gensim tfidf\n",
    "    temp = corpus2dense(train_tfidf[train_corpus[min(batch_size*i, len(train_corpus)-1):min(batch_size*(i+1), len(train_corpus)-1)]], num_terms=train_tfidf.num_nnz).transpose()\n",
    "    if temp.shape[0]==0:\n",
    "        break\n",
    "    #####We incrementally fit the pca in batches\n",
    "    pca.partial_fit(temp)\n",
    "    i+=1\n",
    "    \n",
    "    #####This line should be removed once we want to run this code on the entire dataset\n",
    "    if i==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "460b6c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40063031 -0.13960853  0.36688407]\n",
      " [-0.00932635  0.00512648 -0.31076145]\n",
      " [-0.41745011 -0.14478315  0.32948692]\n",
      " [-0.00874053  0.0051453  -0.29972531]\n",
      " [ 0.2729355  -0.19642445  0.06004003]\n",
      " [-0.11649877 -0.03346866 -0.131255  ]\n",
      " [ 0.31896489 -0.13724791  0.12150999]\n",
      " [ 0.14831346  0.62669759  0.20950098]\n",
      " [-0.00998653  0.00394718 -0.30063629]\n",
      " [ 0.18249696  0.60496079  0.22683801]]\n",
      "[[-0.13822499 -0.00624933 -0.15842667]\n",
      " [ 0.00738285  0.00620786 -0.13732865]\n",
      " [-0.09583709  0.08742219 -0.04303658]\n",
      " [-0.07827064  0.08027199 -0.04700477]\n",
      " [-0.27413209 -0.09049419  0.20145991]\n",
      " [ 0.02588579 -0.05479543 -0.16933842]\n",
      " [-0.02287835 -0.00068318 -0.41699286]\n",
      " [ 0.48750941 -0.33047302  0.24693167]\n",
      " [ 0.32185933 -0.25251187  0.16115721]\n",
      " [-0.19337242 -0.03303966  0.09069722]]\n"
     ]
    }
   ],
   "source": [
    "#####This cell should generate the transformed data in batches\n",
    "i=0\n",
    "batch_size=10\n",
    "while True:\n",
    "    temp = corpus2dense(train_tfidf[train_corpus[min(batch_size*i, len(train_corpus)-1):min(batch_size*(i+1), len(train_corpus)-1)]], num_terms=train_tfidf.num_nnz).transpose()\n",
    "    if temp.shape[0]==0:\n",
    "        break\n",
    "        \n",
    "    #####out is a matrix containing the dimension reduced columns. Output to a pandas df not yet implemented. \n",
    "    out=pca.transform(temp)\n",
    "    print(out)\n",
    "    i+=1\n",
    "    \n",
    "    #####This line should be removed once we want to run this code on the entire dataset\n",
    "    if i==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5e5ef",
   "metadata": {},
   "source": [
    "## TF-IDF for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec46d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test = pd.read_csv(\"news_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "216c917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = [simple_preprocess(line) for line in news_test['cleaned_words']]\n",
    "test_dict = corpora.Dictionary()\n",
    "test_corpus = [test_dict.doc2bow(line, allow_update=True) for line in test_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5cf66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to do TF-IDF  for test data, BUT we dont want to use the IDF for the test data - the relavant IDF is the training IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097c5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
