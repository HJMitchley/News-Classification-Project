{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18aef592",
   "metadata": {},
   "source": [
    "## TF-IDF for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1987b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b33eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train = pd.read_csv(\"news_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e33d2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = [simple_preprocess(line) for line in news_train['cleaned_words']]\n",
    "train_dict = corpora.Dictionary()\n",
    "train_corpus = [train_dict.doc2bow(line, allow_update=True) for line in train_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6759404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = TfidfModel(train_corpus, smartirs='ntc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93441f87",
   "metadata": {},
   "outputs": [],
   "source": [
    " # apply model to the first corpus document\n",
    "vector = train_tfidf[train_corpus[0]] \n",
    "\n",
    "#etc for other docs in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8563f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b831e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=104651, num_nnz=1769515)\n",
      "[(12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1)]\n",
      "[(12, 0.19625959819721403), (13, 0.18114835462564435), (14, 0.1442343339923965), (15, 0.23020045613760776), (16, 0.1215821887009755), (17, 0.2899603875144407), (18, 0.3392770863731662), (19, 0.17358249142787363), (20, 0.25704246343193127), (21, 0.16477335472980023), (22, 0.4250038937385465), (23, 0.2115885821189835), (24, 0.17199755598460853), (25, 0.37272612481649886), (26, 0.26182342144952586), (27, 0.23472115669795413)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.matutils import corpus2dense\n",
    "print(train_tfidf)\n",
    "print(train_corpus[1])\n",
    "print(train_tfidf[train_corpus[1]])\n",
    "dense_vec = corpus2dense(train_tfidf[train_corpus[1:5]], num_terms=len(train_dict)).transpose()\n",
    "dense_vec\n",
    "#corpus_tfidf_sparse = corpus2csc(corpus_tfidf, num_terms, num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff330593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent completion:       0.00%\n",
      "(3000, 54415)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project_env/lib/python3.10/site-packages/sklearn/decomposition/_incremental_pca.py:335\u001b[0m, in \u001b[0;36mIncrementalPCA.partial_fit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m     mean_correction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m    325\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_ \u001b[38;5;241m/\u001b[39m n_total_samples) \u001b[38;5;241m*\u001b[39m n_samples\n\u001b[1;32m    326\u001b[0m     ) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m-\u001b[39m col_batch_mean)\n\u001b[1;32m    327\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(\n\u001b[1;32m    328\u001b[0m         (\n\u001b[1;32m    329\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingular_values_\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m     )\n\u001b[0;32m--> 335\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m U, Vt \u001b[38;5;241m=\u001b[39m svd_flip(U, Vt, u_based_decision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    337\u001b[0m explained_variance \u001b[38;5;241m=\u001b[39m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (n_total_samples \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project_env/lib/python3.10/site-packages/scipy/linalg/decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    124\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### This cell should fit the pca in batches #####\n",
    "from gensim.matutils import corpus2dense\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca = IncrementalPCA(n_components=950) ###n_components will determine the number of dimensions to keep after applying dimensionality reduction.\n",
    "i=0\n",
    "batch_size=1000 ###If you set the batch size to 1, it will throw an error, since the slice will no longer be a list of lists\n",
    "while True:\n",
    "    print('Percent completion: ' + \"{:10.2f}\".format(100*i*batch_size/len(train_corpus)) + '%')\n",
    "    #####Temp is a numpy array corresponding to the dense rows generated from the gensim tfidf\n",
    "    temp = corpus2dense(train_tfidf[train_corpus[min(batch_size*i, len(train_corpus)-1):min(batch_size*(i+1), len(train_corpus)-1)]], num_terms=len(train_dict)).transpose()\n",
    "    print(temp.shape)\n",
    "    if temp.shape[0]==0:\n",
    "        break\n",
    "    #####We incrementally fit the pca in batches\n",
    "    pca.partial_fit(temp)\n",
    "    i+=1\n",
    "    \n",
    "    #####This line should be removed once we want to run this code on the entire dataset\n",
    "    if i==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31121e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00314384, 0.00254032, 0.00210664, 0.00182604, 0.00174032,\n",
       "       0.00172537, 0.00167915, 0.00162576, 0.00160155, 0.00156684,\n",
       "       0.00149198, 0.00148234, 0.00145228, 0.00141896, 0.00140582,\n",
       "       0.00138152, 0.00135055, 0.00133839, 0.00132323, 0.0013175 ,\n",
       "       0.00129023, 0.00128372, 0.0012599 , 0.00124494, 0.00123185,\n",
       "       0.00122589, 0.00120789, 0.00120093, 0.00119938, 0.00117671,\n",
       "       0.00117489, 0.00115578, 0.00115161, 0.0011495 , 0.00113882,\n",
       "       0.00113278, 0.00112515, 0.00111606, 0.00111509, 0.00110743,\n",
       "       0.00109876, 0.00109087, 0.00108623, 0.00108286, 0.00107521,\n",
       "       0.00106363, 0.00105319, 0.00104927, 0.0010428 , 0.00104237,\n",
       "       0.00103111, 0.00103059, 0.00102241, 0.0010196 , 0.00101462,\n",
       "       0.00100866, 0.00100699, 0.00100584, 0.00099754, 0.00099129,\n",
       "       0.00098093, 0.0009779 , 0.00097698, 0.00097197, 0.00096558,\n",
       "       0.00096042, 0.00095521, 0.00095132, 0.00094671, 0.0009443 ,\n",
       "       0.0009365 , 0.00093446, 0.00092947, 0.00092575, 0.00092221,\n",
       "       0.00092128, 0.00091587, 0.0009122 , 0.00091099, 0.00090584,\n",
       "       0.0009036 , 0.00089894, 0.00089601, 0.000892  , 0.00088866,\n",
       "       0.00088679, 0.00088148, 0.00087894, 0.00087589, 0.00087169,\n",
       "       0.00086897, 0.00086554, 0.00086265, 0.00086188, 0.00085801,\n",
       "       0.00085484, 0.00085147, 0.00084759, 0.00084587, 0.00084523,\n",
       "       0.00084144, 0.00083684, 0.00083172, 0.00082983, 0.00082658,\n",
       "       0.00082581, 0.00082115, 0.0008204 , 0.00081805, 0.00081451,\n",
       "       0.0008121 , 0.00081182, 0.00080909, 0.00080578, 0.00080154,\n",
       "       0.0007995 , 0.00079808, 0.00079426, 0.00079336, 0.00078868,\n",
       "       0.00078761, 0.00078544, 0.00078382, 0.00078117, 0.00078028,\n",
       "       0.00077964, 0.00077659, 0.00077482, 0.00077441, 0.00077101,\n",
       "       0.00076988, 0.00076881, 0.00076779, 0.00076524, 0.00076191,\n",
       "       0.00076121, 0.00075818, 0.00075644, 0.00075471, 0.00075132,\n",
       "       0.00074958, 0.00074766, 0.00074668, 0.00074509, 0.00074327,\n",
       "       0.0007427 , 0.00073985, 0.00073852, 0.00073765, 0.00073515,\n",
       "       0.00073475, 0.00073306, 0.00073019, 0.00072728, 0.00072635,\n",
       "       0.00072583, 0.00072531, 0.000722  , 0.00072149, 0.00071916,\n",
       "       0.00071719, 0.00071566, 0.00071295, 0.00071132, 0.00071073,\n",
       "       0.00070957, 0.00070912, 0.00070586, 0.0007027 , 0.00070196,\n",
       "       0.00070077, 0.0006986 , 0.00069668, 0.00069621, 0.00069396,\n",
       "       0.00069332, 0.00069291, 0.00069019, 0.00068866, 0.00068753,\n",
       "       0.00068647, 0.00068459, 0.00068186, 0.00068124, 0.00067966,\n",
       "       0.00067833, 0.00067745, 0.00067674, 0.00067397, 0.00067281,\n",
       "       0.00067193, 0.00067038, 0.00066936, 0.00066909, 0.00066792,\n",
       "       0.00066634, 0.00066412, 0.00066275, 0.00066127, 0.00065932,\n",
       "       0.00065853, 0.0006569 , 0.00065658, 0.00065488, 0.00065204,\n",
       "       0.00065141, 0.00065046, 0.0006488 , 0.00064856, 0.00064749,\n",
       "       0.00064583, 0.00064524, 0.00064423, 0.00064365, 0.00064337,\n",
       "       0.00064038, 0.00064009, 0.00063696, 0.00063607, 0.00063567,\n",
       "       0.00063389, 0.00063267, 0.00063205, 0.00063112, 0.00063075,\n",
       "       0.00063006, 0.00062854, 0.00062824, 0.00062532, 0.00062387,\n",
       "       0.00062303, 0.0006226 , 0.00062072, 0.00061945, 0.00061844,\n",
       "       0.00061735, 0.00061532, 0.00061486, 0.00061442, 0.00061348,\n",
       "       0.00061176, 0.00061051, 0.00060872, 0.00060856, 0.0006074 ,\n",
       "       0.00060717, 0.00060606, 0.00060442, 0.000604  , 0.00060205,\n",
       "       0.00060055, 0.00059993, 0.00059939, 0.00059884, 0.00059746,\n",
       "       0.00059643, 0.00059606, 0.00059512, 0.00059378, 0.00059292,\n",
       "       0.00059156, 0.00059107, 0.00058999, 0.0005888 , 0.0005875 ,\n",
       "       0.00058652, 0.00058558, 0.00058533, 0.000584  , 0.00058349,\n",
       "       0.00058255, 0.00058154, 0.00058126, 0.00058007, 0.00057881,\n",
       "       0.00057682, 0.00057639, 0.00057547, 0.00057387, 0.00057358,\n",
       "       0.00057296, 0.00057217, 0.00057077, 0.00056999, 0.00056869,\n",
       "       0.00056837, 0.00056765, 0.00056691, 0.00056551, 0.00056461,\n",
       "       0.00056396, 0.00056251, 0.0005622 , 0.00056185, 0.00055996,\n",
       "       0.00055925, 0.00055887, 0.0005582 , 0.00055704, 0.00055621,\n",
       "       0.00055519, 0.00055403, 0.00055336, 0.00055258, 0.00055177,\n",
       "       0.00055105, 0.00055055, 0.00054932, 0.00054903, 0.00054738,\n",
       "       0.00054692, 0.00054661, 0.00054549, 0.00054418, 0.00054379,\n",
       "       0.00054296, 0.00054192, 0.00054142, 0.00054058, 0.00053972,\n",
       "       0.00053947, 0.00053848, 0.00053834, 0.00053597, 0.00053559,\n",
       "       0.00053445, 0.00053427, 0.00053416, 0.00053274, 0.00053233,\n",
       "       0.00053135, 0.00053016, 0.00052967, 0.00052881, 0.00052866,\n",
       "       0.00052846, 0.00052742, 0.0005265 , 0.0005253 , 0.00052434,\n",
       "       0.00052389, 0.00052305, 0.0005224 , 0.00052198, 0.00052077,\n",
       "       0.00052052, 0.00052   , 0.00051857, 0.0005179 , 0.00051733,\n",
       "       0.00051657, 0.00051571, 0.00051519, 0.00051371, 0.00051333,\n",
       "       0.00051307, 0.00051256, 0.00051049, 0.00050996, 0.00050984,\n",
       "       0.00050893, 0.00050882, 0.00050798, 0.0005072 , 0.0005064 ,\n",
       "       0.0005061 , 0.0005052 , 0.00050438, 0.00050333, 0.00050233,\n",
       "       0.00050199, 0.00050111, 0.00050005, 0.00049953, 0.0004988 ,\n",
       "       0.00049867, 0.00049806, 0.00049702, 0.0004962 , 0.00049586,\n",
       "       0.00049521, 0.00049455, 0.00049431, 0.00049307, 0.00049239,\n",
       "       0.00049232, 0.00049161, 0.00049096, 0.00049042, 0.00048983,\n",
       "       0.0004886 , 0.00048834, 0.00048787, 0.00048722, 0.00048637,\n",
       "       0.00048542, 0.0004852 , 0.00048504, 0.0004836 , 0.00048336,\n",
       "       0.00048323, 0.00048213, 0.0004811 , 0.00048102, 0.00048001,\n",
       "       0.00047882, 0.00047837, 0.00047804, 0.00047762, 0.00047705,\n",
       "       0.00047685, 0.00047564, 0.00047543, 0.0004743 , 0.00047392,\n",
       "       0.00047348, 0.00047239, 0.00047163, 0.00047124, 0.00047077,\n",
       "       0.00046963, 0.00046924, 0.00046832, 0.00046759, 0.00046733,\n",
       "       0.000467  , 0.00046644, 0.00046589, 0.0004655 , 0.00046416,\n",
       "       0.00046391, 0.00046352, 0.00046306, 0.00046203, 0.00046153,\n",
       "       0.00046133, 0.00046047, 0.00045961, 0.00045951, 0.00045902,\n",
       "       0.00045851, 0.00045773, 0.00045738, 0.00045705, 0.00045653,\n",
       "       0.00045621, 0.00045584, 0.00045516, 0.00045433, 0.00045366,\n",
       "       0.00045295, 0.00045232, 0.00045193, 0.0004511 , 0.00045063,\n",
       "       0.00044994, 0.00044957, 0.00044932, 0.00044891, 0.00044808,\n",
       "       0.00044774, 0.00044755, 0.00044691, 0.00044593, 0.00044582,\n",
       "       0.00044528, 0.00044466, 0.0004444 , 0.00044345, 0.00044305,\n",
       "       0.00044256, 0.00044218, 0.00044129, 0.00044103, 0.00044057,\n",
       "       0.00044018, 0.00043958, 0.00043891, 0.00043851, 0.00043807,\n",
       "       0.00043732, 0.00043708, 0.00043629, 0.00043595, 0.00043579,\n",
       "       0.00043488, 0.00043424, 0.00043397, 0.00043309, 0.00043255,\n",
       "       0.00043236, 0.00043155, 0.00043114, 0.00042992, 0.00042976,\n",
       "       0.00042947, 0.0004291 , 0.00042851, 0.00042843, 0.00042739,\n",
       "       0.00042709, 0.00042657, 0.00042602, 0.00042543, 0.00042473,\n",
       "       0.00042437, 0.00042349, 0.00042326, 0.00042269, 0.00042213,\n",
       "       0.00042174, 0.00042121, 0.00042084, 0.00041966, 0.00041941,\n",
       "       0.00041925, 0.00041872, 0.0004183 , 0.00041811, 0.0004173 ,\n",
       "       0.00041693, 0.00041651, 0.00041605, 0.00041523, 0.00041494,\n",
       "       0.00041465, 0.00041416, 0.00041384, 0.00041371, 0.00041291,\n",
       "       0.00041206, 0.00041166, 0.00041098, 0.00041093, 0.00041065,\n",
       "       0.0004102 , 0.00041004, 0.00040955, 0.00040917, 0.00040871,\n",
       "       0.00040785, 0.00040757, 0.00040711, 0.00040663, 0.00040615,\n",
       "       0.00040538, 0.00040515, 0.00040453, 0.00040402, 0.00040386,\n",
       "       0.00040336, 0.00040317, 0.00040232, 0.00040158, 0.00040118,\n",
       "       0.00040092, 0.00040059, 0.00040036, 0.00039993, 0.00039965,\n",
       "       0.00039908, 0.00039897, 0.00039819, 0.0003978 , 0.00039719,\n",
       "       0.00039687, 0.00039648, 0.00039572, 0.0003955 , 0.00039526,\n",
       "       0.00039462, 0.00039438, 0.00039396, 0.00039387, 0.00039338,\n",
       "       0.00039312, 0.00039231, 0.00039152, 0.00039127, 0.00039083,\n",
       "       0.00039033, 0.00039009, 0.00038999, 0.00038928, 0.00038906,\n",
       "       0.00038841, 0.0003883 , 0.00038742, 0.00038719, 0.00038676,\n",
       "       0.00038634, 0.00038604, 0.00038558, 0.00038524, 0.00038485,\n",
       "       0.00038403, 0.00038348, 0.00038338, 0.00038298, 0.00038263,\n",
       "       0.00038192, 0.00038142, 0.00038135, 0.00038115, 0.00038074,\n",
       "       0.00038036, 0.00037993, 0.00037957, 0.00037926, 0.00037898,\n",
       "       0.00037796, 0.00037782, 0.00037744, 0.00037644, 0.00037596,\n",
       "       0.00037583, 0.00037574, 0.00037526, 0.00037498, 0.00037462,\n",
       "       0.00037431, 0.00037417, 0.00037365, 0.00037339, 0.00037278,\n",
       "       0.00037207, 0.00037154, 0.00037125, 0.00037049, 0.00037032,\n",
       "       0.00036996, 0.00036968, 0.00036951, 0.00036904, 0.00036882,\n",
       "       0.00036845, 0.00036819, 0.00036808, 0.0003675 , 0.00036666,\n",
       "       0.00036626, 0.00036623, 0.00036571, 0.00036527, 0.00036498,\n",
       "       0.00036451, 0.0003644 , 0.00036421, 0.00036377, 0.00036351,\n",
       "       0.00036322, 0.00036306, 0.00036216, 0.00036179, 0.00036176,\n",
       "       0.00036111, 0.00036031, 0.00036014, 0.00035998, 0.00035939,\n",
       "       0.00035886, 0.0003587 , 0.00035845, 0.00035792, 0.00035719,\n",
       "       0.00035656, 0.00035649, 0.00035587, 0.0003558 , 0.00035562,\n",
       "       0.0003549 , 0.00035477, 0.00035433, 0.00035419, 0.00035381,\n",
       "       0.00035366, 0.00035326, 0.00035237, 0.00035227, 0.00035205,\n",
       "       0.00035144, 0.00035119, 0.0003509 , 0.00035065, 0.00035014,\n",
       "       0.0003499 , 0.00034948, 0.00034904, 0.00034875, 0.00034835,\n",
       "       0.00034808, 0.00034777, 0.00034757, 0.00034722, 0.0003469 ,\n",
       "       0.00034635, 0.0003462 , 0.00034582, 0.00034516, 0.00034506,\n",
       "       0.00034492, 0.00034455, 0.00034414, 0.00034365, 0.00034313,\n",
       "       0.00034302, 0.0003426 , 0.00034243, 0.00034173, 0.00034162,\n",
       "       0.00034101, 0.0003404 , 0.00034018, 0.00034015, 0.00033987,\n",
       "       0.00033929, 0.0003389 , 0.00033835, 0.00033797, 0.00033789,\n",
       "       0.00033731, 0.00033697, 0.00033632, 0.00033609, 0.00033599,\n",
       "       0.00033549, 0.00033533, 0.000335  , 0.00033473, 0.00033439,\n",
       "       0.00033412, 0.00033333, 0.00033322, 0.00033269, 0.00033258,\n",
       "       0.00033206, 0.000332  , 0.00033177, 0.00033131, 0.0003306 ,\n",
       "       0.00033038, 0.00032982, 0.00032938, 0.00032936, 0.0003289 ,\n",
       "       0.00032871, 0.00032834, 0.00032819, 0.00032786, 0.00032753,\n",
       "       0.00032729, 0.00032698, 0.00032671, 0.00032662, 0.00032614,\n",
       "       0.00032602, 0.0003256 , 0.00032517, 0.00032468, 0.00032451,\n",
       "       0.00032438, 0.000324  , 0.00032344, 0.00032321, 0.00032274,\n",
       "       0.00032251, 0.00032201, 0.0003218 , 0.00032142, 0.00032126,\n",
       "       0.00032094, 0.00032063, 0.00032032, 0.00032006, 0.0003194 ,\n",
       "       0.00031918, 0.00031892, 0.0003185 , 0.0003182 , 0.00031805,\n",
       "       0.00031766, 0.00031751, 0.00031718, 0.00031701, 0.00031649,\n",
       "       0.00031607, 0.00031585, 0.00031575, 0.00031525, 0.00031487,\n",
       "       0.00031454, 0.00031407, 0.00031362, 0.00031343, 0.00031336,\n",
       "       0.00031313, 0.00031243, 0.0003122 , 0.00031186, 0.00031126,\n",
       "       0.00031106, 0.00031089, 0.00031062, 0.00031027, 0.00031011,\n",
       "       0.00030961, 0.00030939, 0.00030888, 0.00030818, 0.00030788,\n",
       "       0.00030785, 0.00030748, 0.00030735, 0.00030695, 0.00030679,\n",
       "       0.00030637, 0.00030616, 0.00030588, 0.0003055 , 0.00030537,\n",
       "       0.00030509, 0.00030498, 0.00030396, 0.00030374, 0.00030336,\n",
       "       0.00030321, 0.00030296, 0.00030254, 0.00030234, 0.00030193,\n",
       "       0.0003017 , 0.00030138, 0.00030052, 0.0003004 , 0.00030021,\n",
       "       0.00029972, 0.00029936, 0.00029928, 0.00029904, 0.00029875,\n",
       "       0.0002985 , 0.0002982 , 0.00029801, 0.00029758, 0.00029743,\n",
       "       0.00029731, 0.00029704, 0.0002963 , 0.00029612, 0.00029563,\n",
       "       0.00029534, 0.00029511, 0.00029445, 0.00029441, 0.00029398,\n",
       "       0.00029389, 0.00029344, 0.00029289, 0.0002928 , 0.00029256,\n",
       "       0.00029204, 0.00029174, 0.00029144, 0.00029125, 0.00029085,\n",
       "       0.00029012, 0.00028985, 0.00028983, 0.00028929, 0.00028911,\n",
       "       0.00028869, 0.0002886 , 0.00028824, 0.00028792, 0.00028771,\n",
       "       0.00028708, 0.00028693, 0.00028669, 0.00028653, 0.0002864 ,\n",
       "       0.00028593, 0.00028532, 0.00028513, 0.00028504, 0.00028438,\n",
       "       0.00028431, 0.00028414, 0.00028361, 0.00028333, 0.00028291,\n",
       "       0.00028253, 0.00028224, 0.00028153, 0.00028106, 0.00028085,\n",
       "       0.00028047, 0.00028019, 0.00027968, 0.0002795 , 0.00027936,\n",
       "       0.00027931, 0.00027883, 0.00027781, 0.00027766, 0.00027731,\n",
       "       0.00027711, 0.00027689, 0.00027643, 0.00027584, 0.00027568,\n",
       "       0.00027536, 0.00027489, 0.00027483, 0.00027447, 0.00027418,\n",
       "       0.00027397, 0.00027363, 0.00027312, 0.00027293, 0.00027224,\n",
       "       0.00027185, 0.00027137, 0.0002713 , 0.00027091, 0.0002703 ,\n",
       "       0.00026997, 0.00026979, 0.00026907, 0.00026876, 0.00026861,\n",
       "       0.00026804, 0.0002676 , 0.00026716, 0.0002669 , 0.00026659,\n",
       "       0.00026613, 0.00026546, 0.0002651 , 0.00026491, 0.00026407,\n",
       "       0.00026358, 0.00026327, 0.00026248, 0.00026213, 0.0002617 ,\n",
       "       0.00026076, 0.0002605 , 0.00025949, 0.0002591 , 0.0002583 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####This cell should generate the transformed data in batches\n",
    "i=0\n",
    "batch_size=10\n",
    "while True:\n",
    "    print('Percent completion: ' + \"{:10.2f}\".format(100*i*batch_size/len(train_corpus)) + '%')\n",
    "    temp = corpus2dense(train_tfidf[train_corpus[min(batch_size*i, len(train_corpus)-1):min(batch_size*(i+1), len(train_corpus)-1)]], num_terms=len(train_dict)).transpose()\n",
    "    if temp.shape[0]==0:\n",
    "        break\n",
    "        \n",
    "    #####out is a matrix containing the dimension reduced columns. Output to a pandas df not yet implemented. \n",
    "    out=pca.transform(temp)\n",
    "    print(out)\n",
    "    i+=1\n",
    "    \n",
    "    #####This line should be removed once we want to run this code on the entire dataset\n",
    "    if i==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5e5ef",
   "metadata": {},
   "source": [
    "## TF-IDF for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec46d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test = pd.read_csv(\"news_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = [simple_preprocess(line) for line in news_test['cleaned_words']]\n",
    "test_dict = corpora.Dictionary()\n",
    "test_corpus = [test_dict.doc2bow(line, allow_update=True) for line in test_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to do TF-IDF  for test data, BUT we dont want to use the IDF for the test data - the relavant IDF is the training IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097c5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
