{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad77da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import pprint\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75a4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_df = pd.read_csv(\"News_ds_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f76539",
   "metadata": {},
   "source": [
    "## Making a df with relevant entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da891ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conjoin categories which are essentially the same, just different names; specifically\n",
    "## \"PARENTS\" and \"PARENTING\"  |  \"WELLNESS\" and \"HEALTY LIVING\"\n",
    "# og_df.loc[og_df.category == \"PARENTS\", 'category'] = \"PARENTING\"\n",
    "# og_df.loc[og_df.category == \"HEALTHY LIVING\", 'category'] = \"WELLNESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c2b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create new df with only categories we want\n",
    "curated_cats = [\"POLITICS\", \"WELLNESS\", \"ENTERTAINMENT\", \"TRAVEL\", \"PARENTING\", \"STYLE & BEAUTY\",\n",
    "                \"QUEER VOICES\", \"FOOD & DRINK\", \"BUSINESS\", \"SPORTS\", \"BLACK VOICES\", \"WORLD NEWS\"]\n",
    "\n",
    "df = og_df.loc[og_df['category'].isin(curated_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01085fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop entries where headline/short_description ends up null\n",
    "df = df[df['short_description_cleaned'].notna()]\n",
    "df = df[df['headline_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5613e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>short_description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>funny tweet parent week sept. 17 23</td>\n",
       "      <td>`` accidentally put grow toothpaste toddler to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>https://www.huffpost.com/entry/puerto-rico-wat...</td>\n",
       "      <td>Puerto Ricans Desperate For Water After Hurric...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>More than half a million people remained witho...</td>\n",
       "      <td>DÁNICA COTO, AP</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>puerto ricans desperate water hurricane fiona ...</td>\n",
       "      <td>half million people remain without water servi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               link  \\\n",
       "3           3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "7           7  https://www.huffpost.com/entry/puerto-rico-wat...   \n",
       "\n",
       "                                            headline    category  \\\n",
       "3  The Funniest Tweets From Parents This Week (Se...   PARENTING   \n",
       "7  Puerto Ricans Desperate For Water After Hurric...  WORLD NEWS   \n",
       "\n",
       "                                   short_description           authors  \\\n",
       "3  \"Accidentally put grown-up toothpaste on my to...  Caroline Bologna   \n",
       "7  More than half a million people remained witho...   DÁNICA COTO, AP   \n",
       "\n",
       "         date                                   headline_cleaned  \\\n",
       "3  2022-09-23                funny tweet parent week sept. 17 23   \n",
       "7  2022-09-22  puerto ricans desperate water hurricane fiona ...   \n",
       "\n",
       "                           short_description_cleaned  \n",
       "3  `` accidentally put grow toothpaste toddler to...  \n",
       "7  half million people remain without water servi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf118232",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset the indices\n",
    "## Need this in order to accurately match the rows in this df with their if-tdf vectors\n",
    "#df = df.reset_index(drop=True)\n",
    "\n",
    "## drop the second column of indices\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2ec509",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create new column with two cleaned cells concatenated\n",
    "df['cleaned_words'] = df['headline_cleaned'] + ' ' + df['short_description_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0009b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>short_description_cleaned</th>\n",
       "      <th>cleaned_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>funny tweet parent week sept. 17 23</td>\n",
       "      <td>`` accidentally put grow toothpaste toddler to...</td>\n",
       "      <td>funny tweet parent week sept. 17 23 `` acciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.huffpost.com/entry/puerto-rico-wat...</td>\n",
       "      <td>Puerto Ricans Desperate For Water After Hurric...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>More than half a million people remained witho...</td>\n",
       "      <td>DÁNICA COTO, AP</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>puerto ricans desperate water hurricane fiona ...</td>\n",
       "      <td>half million people remain without water servi...</td>\n",
       "      <td>puerto ricans desperate water hurricane fiona ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "7  https://www.huffpost.com/entry/puerto-rico-wat...   \n",
       "\n",
       "                                            headline    category  \\\n",
       "3  The Funniest Tweets From Parents This Week (Se...   PARENTING   \n",
       "7  Puerto Ricans Desperate For Water After Hurric...  WORLD NEWS   \n",
       "\n",
       "                                   short_description           authors  \\\n",
       "3  \"Accidentally put grown-up toothpaste on my to...  Caroline Bologna   \n",
       "7  More than half a million people remained witho...   DÁNICA COTO, AP   \n",
       "\n",
       "         date                                   headline_cleaned  \\\n",
       "3  2022-09-23                funny tweet parent week sept. 17 23   \n",
       "7  2022-09-22  puerto ricans desperate water hurricane fiona ...   \n",
       "\n",
       "                           short_description_cleaned  \\\n",
       "3  `` accidentally put grow toothpaste toddler to...   \n",
       "7  half million people remain without water servi...   \n",
       "\n",
       "                                       cleaned_words  \n",
       "3  funny tweet parent week sept. 17 23 `` acciden...  \n",
       "7  puerto ricans desperate water hurricane fiona ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79dd9020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 122005 entries, 3 to 209485\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   link                       122005 non-null  object\n",
      " 1   headline                   122005 non-null  object\n",
      " 2   category                   122005 non-null  object\n",
      " 3   short_description          122005 non-null  object\n",
      " 4   authors                    101022 non-null  object\n",
      " 5   date                       122005 non-null  object\n",
      " 6   headline_cleaned           122005 non-null  object\n",
      " 7   short_description_cleaned  122005 non-null  object\n",
      " 8   cleaned_words              122005 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ae15ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>short_description_cleaned</th>\n",
       "      <th>cleaned_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WORLD NEWS</th>\n",
       "      <td>3297</td>\n",
       "      <td>3297</td>\n",
       "      <td>3297</td>\n",
       "      <td>2678</td>\n",
       "      <td>3297</td>\n",
       "      <td>3297</td>\n",
       "      <td>3297</td>\n",
       "      <td>3297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK VOICES</th>\n",
       "      <td>4176</td>\n",
       "      <td>4176</td>\n",
       "      <td>4176</td>\n",
       "      <td>3312</td>\n",
       "      <td>4176</td>\n",
       "      <td>4176</td>\n",
       "      <td>4176</td>\n",
       "      <td>4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPORTS</th>\n",
       "      <td>4406</td>\n",
       "      <td>4406</td>\n",
       "      <td>4406</td>\n",
       "      <td>3601</td>\n",
       "      <td>4406</td>\n",
       "      <td>4406</td>\n",
       "      <td>4406</td>\n",
       "      <td>4406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUSINESS</th>\n",
       "      <td>5130</td>\n",
       "      <td>5130</td>\n",
       "      <td>5130</td>\n",
       "      <td>4372</td>\n",
       "      <td>5130</td>\n",
       "      <td>5130</td>\n",
       "      <td>5130</td>\n",
       "      <td>5130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEER VOICES</th>\n",
       "      <td>5596</td>\n",
       "      <td>5596</td>\n",
       "      <td>5596</td>\n",
       "      <td>4695</td>\n",
       "      <td>5596</td>\n",
       "      <td>5596</td>\n",
       "      <td>5596</td>\n",
       "      <td>5596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOOD &amp; DRINK</th>\n",
       "      <td>6329</td>\n",
       "      <td>6329</td>\n",
       "      <td>6329</td>\n",
       "      <td>4526</td>\n",
       "      <td>6329</td>\n",
       "      <td>6329</td>\n",
       "      <td>6329</td>\n",
       "      <td>6329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARENTING</th>\n",
       "      <td>8781</td>\n",
       "      <td>8781</td>\n",
       "      <td>8781</td>\n",
       "      <td>6512</td>\n",
       "      <td>8781</td>\n",
       "      <td>8781</td>\n",
       "      <td>8781</td>\n",
       "      <td>8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAVEL</th>\n",
       "      <td>9419</td>\n",
       "      <td>9419</td>\n",
       "      <td>9419</td>\n",
       "      <td>8022</td>\n",
       "      <td>9419</td>\n",
       "      <td>9419</td>\n",
       "      <td>9419</td>\n",
       "      <td>9419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STYLE &amp; BEAUTY</th>\n",
       "      <td>9793</td>\n",
       "      <td>9793</td>\n",
       "      <td>9793</td>\n",
       "      <td>7273</td>\n",
       "      <td>9793</td>\n",
       "      <td>9793</td>\n",
       "      <td>9793</td>\n",
       "      <td>9793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTERTAINMENT</th>\n",
       "      <td>14754</td>\n",
       "      <td>14754</td>\n",
       "      <td>14754</td>\n",
       "      <td>13443</td>\n",
       "      <td>14754</td>\n",
       "      <td>14754</td>\n",
       "      <td>14754</td>\n",
       "      <td>14754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WELLNESS</th>\n",
       "      <td>17922</td>\n",
       "      <td>17922</td>\n",
       "      <td>17922</td>\n",
       "      <td>12927</td>\n",
       "      <td>17922</td>\n",
       "      <td>17922</td>\n",
       "      <td>17922</td>\n",
       "      <td>17922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLITICS</th>\n",
       "      <td>32402</td>\n",
       "      <td>32402</td>\n",
       "      <td>32402</td>\n",
       "      <td>29661</td>\n",
       "      <td>32402</td>\n",
       "      <td>32402</td>\n",
       "      <td>32402</td>\n",
       "      <td>32402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 link  headline  short_description  authors   date  \\\n",
       "category                                                             \n",
       "WORLD NEWS       3297      3297               3297     2678   3297   \n",
       "BLACK VOICES     4176      4176               4176     3312   4176   \n",
       "SPORTS           4406      4406               4406     3601   4406   \n",
       "BUSINESS         5130      5130               5130     4372   5130   \n",
       "QUEER VOICES     5596      5596               5596     4695   5596   \n",
       "FOOD & DRINK     6329      6329               6329     4526   6329   \n",
       "PARENTING        8781      8781               8781     6512   8781   \n",
       "TRAVEL           9419      9419               9419     8022   9419   \n",
       "STYLE & BEAUTY   9793      9793               9793     7273   9793   \n",
       "ENTERTAINMENT   14754     14754              14754    13443  14754   \n",
       "WELLNESS        17922     17922              17922    12927  17922   \n",
       "POLITICS        32402     32402              32402    29661  32402   \n",
       "\n",
       "                headline_cleaned  short_description_cleaned  cleaned_words  \n",
       "category                                                                    \n",
       "WORLD NEWS                  3297                       3297           3297  \n",
       "BLACK VOICES                4176                       4176           4176  \n",
       "SPORTS                      4406                       4406           4406  \n",
       "BUSINESS                    5130                       5130           5130  \n",
       "QUEER VOICES                5596                       5596           5596  \n",
       "FOOD & DRINK                6329                       6329           6329  \n",
       "PARENTING                   8781                       8781           8781  \n",
       "TRAVEL                      9419                       9419           9419  \n",
       "STYLE & BEAUTY              9793                       9793           9793  \n",
       "ENTERTAINMENT              14754                      14754          14754  \n",
       "WELLNESS                   17922                      17922          17922  \n",
       "POLITICS                   32402                      32402          32402  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.groupby(\"category\").count().sort_values(by=[\"link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "747aae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename single word columns in df \n",
    "## (it causes problems if one of the words from text is same as another column name)\n",
    "df = df.rename(columns={\"link\":\"link_col\", \n",
    "                        \"headline\":\"headline_col\", \n",
    "                        \"category\":\"category_col\",\n",
    "                        \"authors\":\"authors_col\", \n",
    "                        \"date\":\"date_col\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae398aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news_train, news_test = train_test_split(df,\n",
    "                                         random_state = 546,\n",
    "                                         shuffle = True,\n",
    "                                         test_size = .2,\n",
    "                                         stratify = df['category_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de2863b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset the indices\n",
    "## Need this in order to accurately match the rows in this df with their if-tdf vectors\n",
    "news_train = news_train.reset_index(drop=True)\n",
    "news_test = news_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to csv\n",
    "train_df.to_csv('./news_train.csv') \n",
    "test_df.to_csv('./news_test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aef592",
   "metadata": {},
   "source": [
    "## TF-IDF for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1987b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e33d2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = [simple_preprocess(line) for line in news_train['cleaned_words']]\n",
    "train_dict = corpora.Dictionary()\n",
    "train_corpus = [train_dict.doc2bow(line, allow_update=True) for line in train_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6759404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = TfidfModel(train_corpus, smartirs='ntc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93441f87",
   "metadata": {},
   "outputs": [],
   "source": [
    " # apply model to the first corpus document\n",
    "vector = train_tfidf[train_corpus[0]] \n",
    "\n",
    "#etc for other docs in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd8563f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.21744169315184333),\n",
       " (1, 0.3618448148680886),\n",
       " (2, 0.21802640014757815),\n",
       " (3, 0.2238970949090863),\n",
       " (4, 0.19056966589632973),\n",
       " (5, 0.25140181801266853),\n",
       " (6, 0.13174885342746356),\n",
       " (7, 0.26769462667343497),\n",
       " (8, 0.17802583109395193),\n",
       " (9, 0.17648047015395238),\n",
       " (10, 0.27287366056311535),\n",
       " (11, 0.3298001145213803),\n",
       " (12, 0.2366594716946781),\n",
       " (13, 0.28469782194419974),\n",
       " (14, 0.3904573166949825)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5e5ef",
   "metadata": {},
   "source": [
    "## TF-IDF for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "216c917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = [simple_preprocess(line) for line in news_test['cleaned_words']]\n",
    "test_dict = corpora.Dictionary()\n",
    "test_corpus = [test_dict.doc2bow(line, allow_update=True) for line in test_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5cf66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to do TF-IDF  for test data, BUT we dont want to use the IDF for the test data - the relavant IDF is the training IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097c5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
