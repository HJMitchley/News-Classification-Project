{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad77da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import pprint\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d75a4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_df = pd.read_pickle(\"News_ds_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f76539",
   "metadata": {},
   "source": [
    "## Making a df with relevant entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da891ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conjoin categories which are essentially the same, just different names; specifically\n",
    "## \"PARENTS\" and \"PARENTING\"  |  \"WELLNESS\" and \"HEALTY LIVING\"\n",
    "#og_df.loc[og_df.category == \"PARENTS\", 'category'] = \"PARENTING\"\n",
    "#og_df.loc[og_df.category == \"HEALTHY LIVING\", 'category'] = \"WELLNESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c2b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create new df with only categories we want\n",
    "curated_cats = [\"POLITICS\", \"WELLNESS\", \"ENTERTAINMENT\", \"TRAVEL\", \"PARENTING\", \"STYLE & BEAUTY\",\n",
    "                \"QUEER VOICES\", \"FOOD & DRINK\", \"BUSINESS\", \"SPORTS\", \"BLACK VOICES\", \"WORLD NEWS\"]\n",
    "\n",
    "df = og_df.loc[og_df['category'].isin(curated_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01085fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop entries where headline/short_description ends up null\n",
    "df = df[df['short_description_cleaned'].notna()]\n",
    "df = df[df['headline_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5613e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>short_description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>funny tweet parent week sept. 17 23</td>\n",
       "      <td>accidentally put grow toothpaste toddler tooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.huffpost.com/entry/puerto-rico-wat...</td>\n",
       "      <td>Puerto Ricans Desperate For Water After Hurric...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>More than half a million people remained witho...</td>\n",
       "      <td>DÁNICA COTO, AP</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>puerto ricans desperate water hurricane fiona ...</td>\n",
       "      <td>half million people remain without water servi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "7  https://www.huffpost.com/entry/puerto-rico-wat...   \n",
       "\n",
       "                                            headline    category  \\\n",
       "3  The Funniest Tweets From Parents This Week (Se...   PARENTING   \n",
       "7  Puerto Ricans Desperate For Water After Hurric...  WORLD NEWS   \n",
       "\n",
       "                                   short_description           authors  \\\n",
       "3  \"Accidentally put grown-up toothpaste on my to...  Caroline Bologna   \n",
       "7  More than half a million people remained witho...   DÁNICA COTO, AP   \n",
       "\n",
       "        date                                   headline_cleaned  \\\n",
       "3 2022-09-23                funny tweet parent week sept. 17 23   \n",
       "7 2022-09-22  puerto ricans desperate water hurricane fiona ...   \n",
       "\n",
       "                           short_description_cleaned  \n",
       "3  accidentally put grow toothpaste toddler tooth...  \n",
       "7  half million people remain without water servi...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf118232",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset the indices\n",
    "## Need this in order to accurately match the rows in this df with their if-tdf vectors\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "## drop the second column of indices\n",
    "#df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e2ec509",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'headline_cleaned_withsw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/project_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project_env/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project_env/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'headline_cleaned_withsw'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## create new column with two cleaned cells concatenated\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_words\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_description_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_words_withsw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheadline_cleaned_withsw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_description_cleaned_withsw\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m=\u001b[39mdf[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_words\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project_env/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'headline_cleaned_withsw'"
     ]
    }
   ],
   "source": [
    "## create new column with two cleaned cells concatenated\n",
    "df['cleaned_words'] = df['headline_cleaned'] + ' ' + df['short_description_cleaned']\n",
    "df['cleaned_words_withsw'] = df['headline_cleaned_withsw'] + ' ' + df['short_description_cleaned_withsw']\n",
    "df=df[df['cleaned_words']!=' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0009b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd9020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae15ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " df.groupby(\"category\").count().sort_values(by=[\"link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747aae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename single word columns in df \n",
    "## (it causes problems if one of the words from text is same as another column name)\n",
    "df = df.rename(columns={\"link\":\"link_col\", \n",
    "                        \"headline\":\"headline_col\", \n",
    "                        \"category\":\"category_col\",\n",
    "                        \"authors\":\"authors_col\", \n",
    "                        \"date\":\"date_col\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae398aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news_train, news_test = train_test_split(df,\n",
    "                                         random_state = 546,\n",
    "                                         shuffle = True,\n",
    "                                         test_size = .2,\n",
    "                                         stratify = df['category_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2863b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset the indices\n",
    "## Need this in order to accurately match the rows in this df with their if-tdf vectors\n",
    "news_train = news_train.reset_index(drop=True)\n",
    "news_test = news_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ttrain, news_tvalid = train_test_split(news_train,\n",
    "                                         random_state = 305,\n",
    "                                         shuffle = True,\n",
    "                                         test_size = .2,\n",
    "                                         stratify = news_train['category_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75977aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ttrain.to_pickle('./news_ttrain.pkl')\n",
    "news_tvalid.to_pickle('./news_tvalid.pkl')\n",
    "news_train.to_pickle('./news_train.pkl') \n",
    "news_test.to_pickle('./news_test.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
